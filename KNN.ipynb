{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONB44cN/W0baSbipXPHHul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iqraiqbal4142/Ai_Note_book/blob/main/KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation\n",
        "is a resampling technique used in machine learning and statistics to assess and validate the performance of a predictive model. Its primary purpose is to provide an estimate of a model's performance on an independent dataset by partitioning the available data into subsets for training and testing. Cross-validation helps ensure that the model's performance is robust and not overly dependent on a specific random split of the data.\n",
        "\n",
        "Here are the key concepts and steps involved in cross-validation:\n",
        "\n",
        "#Data Splitting:\n",
        "The dataset is divided into two (or more) mutually exclusive subsets:\n",
        "\n",
        "#Training Set:\n",
        "This subset is used to train the machine learning model. It serves as the data from which the model learns the underlying patterns and relationships.\n",
        "#Testing (Validation) Set:\n",
        "This subset is used to evaluate the model's performance. It serves as the data to validate how well the model generalizes to unseen examples.\n",
        "#K-Fold Cross-Validation:\n",
        "The most common form of cross-validation is K-Fold Cross-Validation, where the dataset is divided into K equal-sized \"folds\" or subsets. The model is trained and tested K times, each time using a different fold as the validation set while the remaining K-1 folds are used for training. This process helps ensure that the model is evaluated on different portions of the data.\n",
        "\n",
        "#Leave-One-Out Cross-Validation (LOOCV):\n",
        " In LOOCV, K is set to the number of data points in the dataset. For each iteration, one data point is held out as the validation set, and the model is trained on the remaining data points. This process is repeated for each data point, and the results are averaged.\n",
        "\n",
        "#Stratified Cross-Validation:\n",
        " In classification tasks, it's often important to maintain the class distribution when splitting the data. Stratified cross-validation ensures that each fold has a similar class distribution as the entire dataset, reducing the risk of biased evaluation.\n",
        "\n",
        "#Performance Metrics:\n",
        "Various performance metrics can be used to evaluate the model during cross-validation, depending on the problem type. Common metrics include accuracy, precision, recall, F1-score, mean squared error (MSE), and others.\n",
        "\n",
        "#Model Selection and Hyperparameter Tuning:\n",
        " Cross-validation is often used to compare different models or tune hyperparameters. By comparing models' performance across multiple folds, you can select the best-performing model or find optimal hyperparameter settings.\n",
        "\n",
        "#Final Model Evaluation:\n",
        " Once the model selection and hyperparameter tuning are complete, the final model is trained on the entire dataset (or a larger portion if additional data is available) and evaluated on an independent test set. This step provides an estimate of the model's performance in a real-world scenario.\n",
        "\n",
        "Cross-validation is a crucial technique for assessing a model's performance, especially when dealing with limited data. It helps in detecting issues like overfitting (a model that performs well on the training data but poorly on unseen data) and provides a more reliable estimate of a model's generalization performance. Common libraries in Python, such as scikit-learn, provide tools for implementing various cross-validation techniques.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m73Vm1yJklzK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OLgVLabNIC6",
        "outputId": "6433ac49-6709-47e2-c18a-a6d22def52e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target  # Target variable (class labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling (optional but recommended for KNN)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create a KNN classifier\n",
        "k = 3  # Number of neighbors (you can adjust this value)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ]
}